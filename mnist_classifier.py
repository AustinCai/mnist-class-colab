# -*- coding: utf-8 -*-
"""MNIST Classifier

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nr-0gaoROBg6Th58tlx-FbTrUmIT4h96

Loss spikes: https://stackoverflow.com/questions/47824598/why-does-my-training-loss-have-regular-spikes
* why does making BATCH_SIZE divisor of the number of examples get rid of spikes, and create fractional accurcies?
Why does nn never predict 2?
"""

# Prints GPU and RAM info of the connected Google Colab VM. 

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
    print('Select the Runtime → "Change runtime type" menu to enable a GPU \
          accelerator, ')
    print('and then re-execute this cell.')
else:
    print(gpu_info)

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
    print('To enable a high-RAM runtime, select the Runtime → "Change runtime \
          type"')
    print('menu, and then select High-RAM in the Runtime shape dropdown. \
          Then, ')
    print('re-execute this cell.')
else:
    print('You are using a high-RAM runtime!')

# Uninstalls tensorflow, which is a hack to allow add_embedding to work (another
# block re-installs tensorflow after add_embeddings). 
!pip uninstall tensorflow

PRINT_LOGS = False

import torch 

dev = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

import torchvision
import torchvision.transforms as transforms

def build_ds(train_transform, test_transform):
    # Loads and returns training and test datasets, applying the provided 
    # transform functions. 
    train_ds = torchvision.datasets.MNIST(
        './data', train=True, transform=train_transform, download=True)
    test_ds = torchvision.datasets.MNIST(
        './data', train=False, transform=test_transform, download=True)
    if PRINT_LOGS:
        print("len(train_ds): {}".format(len(train_ds)))
        print("len(test_ds): {}".format(len(test_ds)))

    return train_ds, test_ds

TRAIN_BATCH_SIZE = 60
TEST_BATCH_SIZE = 10000

import torch

def build_dl(train_ds, test_ds): 
    # Constructs and loads training and test dataloaders, which can be iterated 
    # over to return one batch at a time. 
    train_dl = torch.utils.data.DataLoader(
        train_ds, batch_size = TRAIN_BATCH_SIZE, shuffle=True)
    test_dl = torch.utils.data.DataLoader(
        test_ds, batch_size = TEST_BATCH_SIZE)
    if PRINT_LOGS:
        print("len(train_dl): {}".format(len(train_dl)))
        print("len(test_dl): {}".format(len(test_dl)))

    return train_dl, test_dl

def preprocess(x_batch, y_batch):
    # Moves the input batch data to the GPU if available, but does not resize
    # them. 
    return x_batch.to(dev), y_batch.to(dev)


def preprocess_reshape(x_batch, y_batch):
    # Moves the input batch data to the GPU if available, and resizes each 
    # data point to be a 1D vector. 
    return x_batch.view(x_batch.shape[0], -1).to(dev), y_batch.to(dev)


class WrappedDataLoader:
    # Wrapper that applies func to the wrapped dataloader. 
    def __init__(self, dl, func):
        self.dl = dl
        self.func = func

    def __len__(self):
        return len(self.dl)

    def __next__(self):
        return self.next()

    def __iter__(self):
        batches = iter(self.dl)
        for b in batches:
            yield (self.func(*b))


def wrap_dl(train_dl, test_dl):
    # Creates two versions of training and test dataloaders: one the resizes 
    # inputs and one that doesn't. The resized inputs are passed to the model,
    # while the un-resized inputs are displayed as images on tensorboard. 
    train_dl = WrappedDataLoader(train_dl, preprocess)
    test_dl = WrappedDataLoader(test_dl, preprocess)
    train_dlr = WrappedDataLoader(train_dl, preprocess_reshape)
    test_dlr = WrappedDataLoader(test_dl, preprocess_reshape)
    if PRINT_LOGS:
        print("len(train_dl): {}".format(len(train_dl)))
        print("len(test_dl): {} \n".format(len(test_dl)))
        print("len(train_dlr): {}".format(len(train_dlr)))
        print("len(test_dlr): {}".format(len(test_dlr)))

    return train_dl, test_dl, train_dlr, test_dlr

import matplotlib.pyplot as plt


def matplotlib_imshow(img, one_channel=False):
    # Resizes the passed img parameter so that it can be accepted by 
    # plt.imshow(). 
    if one_channel:
        img = img.mean(dim=0)
    npimg = img.cpu().numpy()
    if one_channel:
        plt.imshow(npimg, cmap="Greys")
    else:
        plt.imshow(np.transpose(npimg, (1, 2, 0)))


def show_inputs(writer, train_dl):
    # Displays the input images passed in through train_dl, both to the console
    # and to tensorboard. 
    dataiter = iter(train_dl)
    images, labels = dataiter.__next__()
    if PRINT_LOGS: print("images.shape: {}".format(images.shape))

    img_grid = torchvision.utils.make_grid(images, 8, 2, True, (-1, 1))
    if PRINT_LOGS: print("img_grid.shape: {}".format(img_grid.shape))

    matplotlib_imshow(img_grid, one_channel=True)
    writer.add_image('four_digit_mnist_images', img_grid)
    writer.add_graph(model, images.view(TRAIN_BATCH_SIZE, -1))
    writer.close()

from torch import nn
import torch.nn.functional as F


class Mnist_Linear(nn.Module):
    def __init__(self):
        super().__init__()
        self.lin = nn.Linear(784, 10)

    def forward(self, xb):
        return F.softmax(self.lin(xb), 1)

class Mnist_NN(nn.Module):
    def __init__(self):
        super().__init__()
        self.l1 = nn.Linear(784, 32)
        self.l2 = nn.Linear(32, 32)
        self.l3 = nn.Linear(32, 10) 

    def forward(self, xb):
        a1 = F.relu(self.l1(xb))
        a2 = F.relu(self.l2(a1))
        return F.softmax(self.l3(a2), 1)

import time
import datetime
from torch import optim
from torch.utils.tensorboard import SummaryWriter


def accuracy(yh_batch, y_batch):
    # Caclulates the model's per-batch accuracy given its 
    # (batch_size x class_count) output and (batch_size) labels. Does this by
    # interpreting the models prediction on each data point as the 
    # highest-scored class.
    preds = torch.argmax(yh_batch, dim=1)
    return (preds == y_batch).float().mean()


def fit(writer, model, train_dlr, loss_func, optimizer, epochs):
    # Trains the model. For each epoch, iterates through all batches, 
    # calculating loss and optimizing model weights after each batch. The 
    # running loss is also saved to tensorboard. 
    print('{}-{}e'.format(model, epochs))
    start_time = time.time()
    running_loss = 0.0
    running_accuracy = 0.0

    for epoch in range(epochs):
        for i, (x_batch, y_batch) in enumerate(train_dlr):
            yh_batch = model(x_batch)

            loss = loss_func(yh_batch, y_batch)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            running_accuracy += accuracy(yh_batch, y_batch)
            if i == 0:
                print("Epoch {}: loss {}, accuracy {} (for a single batch).".format(
                    epoch+1, loss.item(), accuracy(yh_batch, y_batch)))
                
            if i % BATCHES_BETWEEN_LOGS == BATCHES_BETWEEN_LOGS-1:
                writer.add_scalar('Training Loss', 
                                running_loss/BATCHES_BETWEEN_LOGS, 
                                global_step=epoch * len(train_dlr) + i)
                writer.add_scalar('Accuracy', 
                                running_accuracy/BATCHES_BETWEEN_LOGS, 
                                global_step=epoch * len(train_dlr) + i)
                running_loss = 0.0
                running_accuracy = 0.0

    writer.close()
    print("--- %s seconds ---" % (time.time() - start_time))

from sklearn.metrics import confusion_matrix
import numpy as np


def print_predictions_per_class(yh_batch_test):
    # Prints the number of times the model predicted each class. Originally 
    # implemented to verify that the confusion matrix worked as expected. 
    if PRINT_LOGS:
        for i in np.unique(y_batch_test.detach().cpu()):
            print("np.where(yh_batch_test == {}): {}".format(
                i, len(np.where(yh_batch_test==i)[0])))


def print_save_cmatrix(writer, y_batch_test, yh_batch_test):
    # Generates a confusion matrix, which is logged to console and saved to
    # tensorboard as an image. 
    cmatrix_test = confusion_matrix(y_batch_test, yh_batch_test)
    cmatrix_test_toprint = np.floor(
        (254.9/cmatrix_test.max())*cmatrix_test).astype(int) + 1
    writer.add_image("Confusion Matrix", cmatrix_test_toprint, dataformats='HW')
    writer.close()
    print(cmatrix_test)


def predict(writer, test_dlr, model, lr, epochs):
    # Runs the model over the test set, saving the model's accuracy alongside
    # its hyperparameters to tensorboard. 
    test_dlr_iter = iter(test_dlr)
    x_batch_test, y_batch_test = test_dlr_iter.__next__()

    yh_batch_test = model(x_batch_test)
    x_batch_test = x_batch_test.detach().cpu()
    y_batch_test = y_batch_test.detach().cpu()
    yh_batch_test = yh_batch_test.detach().cpu()

    accuracy_test = accuracy(yh_batch_test, y_batch_test)
    print("accuracy: {}".format(accuracy_test.item()))

    writer.add_hparams({'lr': lr, 'bsize': TRAIN_BATCH_SIZE, 'epochs': epochs}, 
                       {'accuracy': accuracy_test})
    # writer.close()
    yh_batch_test = torch.argmax(yh_batch_test, dim=1) 
    # print_predictions_per_class(yh_batch_test)
    print_save_cmatrix(writer, y_batch_test, yh_batch_test)

def init_model(model_type):
    if model_type == "nn": return Mnist_NN().to(dev)
    if model_type == "linear": return Mnist_Linear().to(dev)
    return "ERROR"

def init_transforms():
    test_trans = transforms.Compose([transforms.ToTensor(), 
                                     transforms.Normalize((0.5,), (0.5,))])
    vflip_trans = transforms.Compose([transforms.RandomVerticalFlip(p=0.5), 
                                      transforms.ToTensor(), 
                                      transforms.Normalize((0.5,), (0.5,))])
    hflip_trans = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5), 
                                      transforms.ToTensor(), 
                                      transforms.Normalize((0.5,), (0.5,))])
    contrast_trans = transforms.Compose([transforms.ColorJitter(contrast=1.0), 
                                         transforms.ToTensor(), 
                                         transforms.Normalize((0.5,), (0.5,))])
    return test_trans, vflip_trans, hflip_trans, contrast_trans

"""###Start Runs Here (for the most part)"""

'''
CONSTANT
'''
# A list of tuples, with each tuple representing a hyperparameter configuration
# of the model to be run in sequence. 
#
# Specify tuples as such: (model type, epochs, learning rate, augmentation). 
# For example: ("nn", 3, 0.03, "vflip").
RUN_SPECS = [("nn", 1, 0.15, "none"),
             ("nn", 1, 0.15, "vflip"),
             ("nn", 1, 0.15, "hflip"),
             ("nn", 1, 0.15, "contrast")]

# Constants indicating the tuple index each hyperparameter is specified. These
# should not be modified by the user. 
MODEL_IDX = 0
EPOCHS_IDX = 1
LR_IDX = 2
TRANS_IDX = 3

BATCHES_BETWEEN_LOGS = 10

test_transform, vflip_transform, hflip_transform, contrast_transform = \
    init_transforms()
train_transforms = {"none": test_transform,
                    "vflip": vflip_transform,
                    "hflip": hflip_transform,
                    "contrast": contrast_transform}

for spec in RUN_SPECS:
    # Iterates through each model configuration specified by RUN_SPECS. 
    # Initializes and trains each model with its specified configuration, 
    # evaluates each on the test set, and records its performance to 
    # tensorboard.
    writer = SummaryWriter('runs/{}-{}e-{}bs-{}lr-{}-{}'.format(
        spec[MODEL_IDX], 
        spec[EPOCHS_IDX], 
        TRAIN_BATCH_SIZE, 
        spec[LR_IDX], 
        spec[TRANS_IDX],
        datetime.datetime.now().strftime("%H:%M:%S")))
 
    train_ds, test_ds = build_ds(
        train_transforms[spec[TRANS_IDX]], test_transform)
    train_dl, test_dl = build_dl(train_ds, test_ds)
    train_dl, test_dl, train_dlr, test_dlr = wrap_dl(train_dl, test_dl)

    loss_func = nn.CrossEntropyLoss() # TODO: hyperparameterize 
    model = init_model(spec[MODEL_IDX])

    # TODO: hyperparameterize
    optimizer = optim.SGD(model.parameters(), lr=spec[LR_IDX]) 

    show_inputs(writer, train_dl)
    fit(writer, model, train_dlr, loss_func, optimizer, spec[EPOCHS_IDX])
    predict(writer, test_dlr, model, spec[LR_IDX], spec[EPOCHS_IDX])
    writer.close()

# Reinstalls tensorflow (which was uninstalled to get add_embeddings to work),
# which is required for tensorboard. If the installation reccomends you restart
# runtime, ignore it. 
!pip install tensorflow
print("DO NOT RESTART RUNTIME: tensorflow needs to be installed AFTER " + 
      "writer.add_embeddings for tensorboard to work properly. ")

# Commented out IPython magic to ensure Python compatibility.
import torch.utils.tensorboard

# %reload_ext tensorboard
# %tensorboard --logdir=runs